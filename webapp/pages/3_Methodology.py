import sys
import os
import streamlit as st

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, project_root)

from src.utils.stats import (
    basic_counts, top_k_words, word_length, 
    split_sentences, sentence_statistics
)

st.title("Methodology")
st.write("Detailed explanation of implementation approaches and techniques used in this project.")

st.divider()

# Dataset Details Section
st.header("Dataset Details")
st.write("""
This project uses a dataset of 12,000 restaurant reviews with ratings from 1 to 5 stars. 
The dataset was balanced to create three sentiment classes:

- **Negative**: Ratings 1-2 (4,000 reviews each)
- **Neutral**: Rating 3 (4,000 reviews)
- **Positive**: Ratings 4-5 (2,000 reviews each)

The reviews contain real-world text with varying lengths, informal language, and natural sentiment expressions,
making it a practical testbed for comparing different NLP approaches.
""")

st.divider()

# Rule-Based Section
st.header("1. Rule-Based Technique")

st.subheader("Overview")
st.write("""
Rule-based NLP is not ML-based. It relies solely on linguistic rules and patterns to try to understand human language. 
But these "rules" have limitations and therefore struggle to pick up on the real meaning and semantics of the text. 
It is purely a **syntax-based technique** and, out of the three techniques, obviously tends to perform the weakest, 
as the other methods are more complex and try to understand the true meaning rather than just focus on the syntax.
""")

st.subheader("Tokenization")
st.write("""
I used rule-based technique for tokenization, sentiment analysis, as well as topic detection. For tokenization, 
I used something called **regular expression (regex)**, which performs a search pattern to match and manipulate text. 
I utilized the `re` library of Python for this. With the help of regex, I tokenized texts and removed **stop words** 
such as (I, the, a, me, etc). Stop words are words that frequently pop up and therefore don't really add much value 
to the text. Not to mention, they especially don't help you with finding the sentiment of the text.
""")

st.subheader("Sentiment Analysis Logic")
st.write("""
For sentiment analysis using rule-based, I continued to use the tokens generated by my `regex_tokenizer`. 
The logic for this was quite simple:

1. I have three sets: `POSITIVE_WORDS`, `NEGATIVE_WORDS`, and `NEGATION_WORDS`
2. Every time a token appears in my positive words set, I increment its value by one
3. Same logic for the tokens that appeared in the negative set
4. I also had to consider **negations** in human language

**Example of negation handling:**  
Without negation, the following sentence would be ruled out as positive: *"The pizza was not good!"*  
Clearly this is a negative sentiment, but since the whole input sequence contains one positive word "good", 
this would be ruled out as positive. So negation matters because if you have a word like "never" before "good" 
(*"never good"*), then this should actually be counted as negative, not positive.
""")

st.subheader("Classification & Confidence")
st.write("""
After looping through the tokens, we get the final sum for the total number of positive and negative words:

- If `num_positive > num_negative` → classify as **positive**
- If `num_negative > num_positive` → classify as **negative**  
- If `num_positive == num_negative` → classify as **neutral**

Along with the prediction, I also return the **confidence** of each prediction using the normalized confidence formula:

`confidence = |pos - neg| / (pos + neg)`

This returns a range from 0 to 1.
""")

st.subheader("Performance")
st.write("""
This technique achieved an **accuracy of ~41%** on my dataset. While VERY quick, the performance really wasn't that good. 
At first, it looks like it performed "better" than the LLM & BERT method for classifying the `neutral` class. 
But really it just predicted `neutral` a lot for most data points, and picking `neutral` shows that rule-based has 
ambiguity and didn't commit to either `positive` or `negative` class.

My positive & negative words lists weren't really that long, so perhaps a longer set would improve performance. 
But that's a maybe, and rule-based has limits with its use cases—sentiment analysis isn't one that it excels at.
""")

st.subheader("Additional Stats Implementation")
st.write("""
I also tried doing some rule-based stats in my `stats.py` for fun & from scratch, including:

- **Basic counts**: Number of characters, words, and sentences
- **Top K words**: Most frequent words in the text
- **Word length statistics**: Longest word, shortest word, average word length
- **Sentence splitting**: Breaking input into individual sentences
- **Sentence statistics**: Longest sentence, shortest sentence, average sentence length
""")

# Interactive Stats Demo
st.subheader("Try the Stats Functions!")
st.write("Enter text below to see rule-based text statistics in action:")

user_stats_input = st.text_area(
    "Enter your text for analysis",
    placeholder="Type or paste any text here to analyze its statistics...",
    height=120
)

if st.button("Analyze Text Statistics"):
    if user_stats_input:
        st.write("---")
        
        # Basic Counts
        num_chars, num_words, num_sentences = basic_counts(user_stats_input)
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Characters", num_chars)
        with col2:
            st.metric("Words", num_words)
        with col3:
            st.metric("Sentences", num_sentences)
        
        st.write("")
        
        # Word Statistics
        st.write("**Word Statistics:**")
        longest, shortest, avg_len = word_length(user_stats_input)
        col1, col2, col3 = st.columns(3)
        with col1:
            st.write(f"Longest word: **{longest}** ({len(longest)} chars)")
        with col2:
            st.write(f"Shortest word: **{shortest}** ({len(shortest)} chars)")
        with col3:
            st.write(f"Avg word length: **{avg_len}** chars")
        
        st.write("")
        
        # Top K Words
        st.write("**Top 5 Most Frequent Words:**")
        top_words = top_k_words(user_stats_input, 5)
        st.write(", ".join([f"**{word}**" for word in top_words]))
        
        st.write("")
        
        # Sentence Statistics
        if num_sentences > 0:
            st.write("**Sentence Statistics:**")
            try:
                longest_sen, shortest_sen, avg_sen = sentence_statistics(user_stats_input)
                st.write(f"- Longest sentence: *\"{longest_sen}\"* ({len(longest_sen.split())} words)")
                st.write(f"- Shortest sentence: *\"{shortest_sen}\"* ({len(shortest_sen.split())} words)")
                st.write(f"- Average sentence length: **{avg_sen}** words")
            except:
                st.write("Could not analyze sentence statistics for this text.")
    else:
        st.warning("Please enter some text to analyze!")

st.divider()

# BERT Section
st.header("2. Bidirectional Encoder Representations from Transformers (BERT)")
st.info("Still writing...")

st.divider()

# LLM Section
st.header("3. LLM Approach (Gemini-2.5-Flash)")
st.info("Still writing...")
